---
{"dg-publish":true,"dg-path":"数学/概率论/切比雪夫不等式.md","permalink":"/数学/概率论/切比雪夫不等式/","dgPassFrontmatter":true,"noteIcon":"","created":"2024-10-16T20:17:47.889+08:00","updated":"2024-10-16T20:17:47.889+08:00"}
---

(terminology::**Chebyshev's Inequality**)   切比雪夫不等式
>[!important] Description
>前置知识：[[随机变量\|随机变量]]  [[期望\|期望]]  [[方差\|方差]]

***

随机变量 $X$  有期望: $E(X)=\mu$    方差: $D(X)=\sigma^{2}$
则对于任何给定的 $\varepsilon>0$，有
$$\begin{align}
P\left\{|X-\mu | \geq \varepsilon \right\}\leq \dfrac{\sigma^{2}}{\varepsilon^{2}}
\end{align}$$

$$\begin{align}
P\left\{|X-\mu|< \varepsilon \right\} \geq 1- \dfrac{\sigma^{2}}{\varepsilon^{2}}
\end{align}$$
-  $\sigma^{2}$ 越小，事件 $\left\{|X-E(X)|<\varepsilon \right\}$ 的概率越大
	也即：方差越小，随机变量集中在期望附近的可能性越大
	方差刻画了随机变量取值的离散程度
	
- 当方差已知时，切比雪夫不等式给出了随机变量 $X$ 偏差期望值概率的上界
- 它适用于所有具有有限期望值和方差的随机变量。
- 它提供了一个概率上界，即它给出了一个概率的上限，实际概率可能更小。
- 它不依赖于随机变量的具体分布，只依赖于期望值和方差。
- 它是一种弱大数定律，因为它只给出了一个概率的上界，并没有给出概率的确切值。

在其他类型的分布特性（如正态分布）不适用或未知的情况下。它可以用来估计数据的离散程度，或者在没有足够数据来确定分布的情况下进行概率估计
### 证明：

$$\begin{align}
P\left\{|X-\mu|\geq\varepsilon \right\}&=\int_{|X-\mu|\geq\varepsilon} f(x)\, dx  \\
& \leq \int  _{|X-\mu|\geq\varepsilon}  \dfrac{(x-\mu)^{2}}{\varepsilon^{2}} f(x)\, dx  \\
&\leq \dfrac{1}{\varepsilon^{2}}\int _{-\infty}^{+\infty} (x-\mu)^{2}f(x)\, dx  \\
&=\dfrac{D(X)}{\varepsilon^{2}}=\dfrac{\sigma^{2}}{\varepsilon^{2}}
\end{align}$$


